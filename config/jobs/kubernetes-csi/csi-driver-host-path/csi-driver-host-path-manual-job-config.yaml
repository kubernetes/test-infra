# Derived from csi-driver-host-path-config.yaml, modified and maintained manually.

presubmits:
  kubernetes-csi/csi-driver-host-path:
  - name: pull-kubernetes-csi-csi-driver-host-distributed-on-kubernetes-1-21
    # Will only work on branches with https://github.com/kubernetes-csi/csi-driver-host-path/pull/248 merged.
    # That was merged into master and we don't maintain any older branches, so always
    # running it is fine.
    always_run: true
    optional: true
    decorate: true
    skip_report: false
    skip_branches: []
    labels:
      preset-service-account: "true"
      preset-dind-enabled: "true"
      preset-kind-volume-mounts: "true"
    annotations:
      testgrid-dashboards: sig-storage-csi-csi-driver-host-path
      testgrid-tab-name: distributed-on-kubernetes-1-19
      description: Kubernetes-CSI pull job in repo csi-driver-host-path for distributed deployment on Kubernetes 1.19, with CSIStorageCapacity
    spec:
      containers:
      # We need this image because it has Docker in Docker and go.
      - image: gcr.io/k8s-testimages/kubekins-e2e:v20210512-b8d1b30-master
        command:
        - runner.sh
        args:
        - ./.prow.sh
        env:
        - name: CSI_PROW_KUBERNETES_VERSION
          value: "1.21.0"
        - name: CSI_PROW_DEPLOYMENT
          value: "kubernetes-distributed"
        - name: CSI_PROW_DRIVER_VERSION
          value: "v1.7.2"
        - name: CSI_SNAPSHOTTER_VERSION
          value: "v3.0.3"
        - name: CSI_PROW_TESTS
          value: "sanity serial parallel serial-alpha parallel-alpha"
        - name: CSI_PROW_SANITY_POD
          value: csi-hostpath-socat-0
        - name: CSI_PROW_SANITY_CONTAINER
          value: socat
        # docker-in-docker needs privileged mode
        securityContext:
          privileged: true
        resources:
          requests:
            # these are both a bit below peak usage during build
            # this is mostly for building kubernetes
            memory: "9000Mi"
            # during the tests more like 3-20m is used
            cpu: 2000m
periodics:
- interval: 6h
  # 1.21 is used because the distributed deployment also
  # uses capacity tracking which is enabled by default in
  # Kubernetes 1.21.
  #
  # This job is meant to detect regressions in upcoming releases
  # that slipped through pre-merge testing, so we have to use canary
  # images.
  name: ci-kubernetes-csi-canary-distributed-on-kubernetes-1-21
  decorate: true
  extra_refs:
  - org: kubernetes-csi
    repo: csi-driver-host-path
    base_ref: master
  labels:
    preset-service-account: "true"
    preset-dind-enabled: "true"
    preset-bazel-remote-cache-enabled: "true"
    preset-kind-volume-mounts: "true"
  annotations:
    testgrid-dashboards: sig-storage-csi-ci
    testgrid-tab-name: distributed-on-master
    testgrid-alert-email: kubernetes-sig-storage-test-failures@googlegroups.com
    description: periodic Kubernetes-CSI job for distributed provisioning on Kubernetes master, with CSIStorageCapacity
  spec:
    containers:
    # We need this image because it has Docker in Docker and go.
    - image: gcr.io/k8s-testimages/kubekins-e2e:v20210512-b8d1b30-master
      command:
      - runner.sh
      args:
      - ./.prow.sh
      env:
      - name: CSI_PROW_KUBERNETES_VERSION
        value: "1.21.0"
      - name: CSI_PROW_USE_BAZEL
        value: "false"
      - name: CSI_SNAPSHOTTER_VERSION
        value: "master"
      - name: CSI_PROW_BUILD_JOB
        value: "false"
      - name: CSI_PROW_TESTS
        value: "sanity serial parallel serial-alpha parallel-alpha"
      - name: CSI_PROW_SANITY_POD
        value: csi-hostpath-socat-0
      - name: CSI_PROW_SANITY_CONTAINER
        value: socat
      - name: CSI_PROW_DEPLOYMENT
        value: "kubernetes-distributed"
      # Replace images....
      - name: CSI_PROW_HOSTPATH_CANARY
        value: "canary"
      # docker-in-docker needs privileged mode
      securityContext:
        privileged: true
      resources:
        requests:
          # these are both a bit below peak usage during build
          # this is mostly for building kubernetes
          memory: "9000Mi"
          # during the tests more like 3-20m is used
          cpu: 2000m
