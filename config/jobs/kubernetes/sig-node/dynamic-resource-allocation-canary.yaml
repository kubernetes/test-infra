# This file contains canary periodic and presubmit jobs which run tests covering
# Dynamic Resource Allocation (DRA).
#
# The intent is to make all changes to DRA jobs first for these canary jobs,
# then copy the changes into dynamic-resource-allocation.yaml. Unless some
# experimental changes are being tested, a diff between the two files should
# be limited to:
# - this comment
# - job names
# - interval for the periodic jobs
#
# This command can be used to check this:
#    diff dynamic-resource-allocation.yaml <(sed -e 's/-canary//' dynamic-resource-allocation-canary.yaml)


# `templates` has no special meaning. It just holds YAML anchors (= re-usable content)
# that get referenced below via YAML aliases: `<<: *job` includes the content
# and then allows adding or overwriting fields. This is done at the root. If a field
# contains lists or objects, that content gets replaced instead of merged.
#
# Lists cannot be extended the same way (https://github.com/yaml/yaml/issues/35).
#
# If unsure what the expanded jobs look like or to test parsing, run `go test -v .`
templates:
  - &job
    cluster: eks-prow-build-cluster
    annotations: &annotations
      testgrid-dashboards: sig-node-dynamic-resource-allocation
      # Alerting is enabled also for PRs. If someone repeatedly tests a broken
      # PR where the change introduced by the PR breaks tests, an alert will
      # eventually be triggered. This is a good thing because then we can
      # show the PR author how to do local testing...
      #
      # Disabled for canary jobs, enabled for real jobs.
      testgrid-alert-email: # patrick.ohly@intel.com,eduard.bartosh@intel.com # #wg-device-management on Slack
      fork-per-release: "false" # Only for canary jobs, must be true for real jobs.
    decorate: true

  - &kubernetes-master
    org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes

  - &test-infra-master
    org: kubernetes
    repo: test-infra
    base_ref: master
    path_alias: k8s.io/test-infra

  - &periodic-job
    interval: 1000000h # Run only once on creation and when manually triggered.
    extra_refs:
    - *kubernetes-master

  - &periodic-node-job
    <<: *periodic-job
    extra_refs:
    - *kubernetes-master
    - *test-infra-master # For test-infra/jobs/e2e_node files.

  - &presubmit-job
    skip_branches:
    - release-\d+\.\d+  # per-release image
    always_run: false
    optional: true
    skip_report: false
    # run_if_changed is set judiciously on some jobs.

  - &e2e-kind-job
    <<: *job
    decoration_config:
      timeout: 3h
    labels:
      preset-service-account: "true"
      preset-dind-enabled: "true"
      preset-kind-volume-mounts: "true"
    decoration_config:
      timeout: 3h
    spec:
      containers:
      - &e2e-kind-container
        image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20241128-8df65c072f-master
        command:
        - runner.sh
        - /bin/sh
        - -xce
        - |
          make WHAT="github.com/onsi/ginkgo/v2/ginkgo k8s.io/kubernetes/test/e2e/e2e.test"
          curl -sSL https://kind.sigs.k8s.io/dl/latest/linux-amd64.tgz | tar xvfz - -C "${PATH%%:*}/" kind
          kind build node-image --image=dra/node:latest .
          trap 'kind export logs "${ARTIFACTS}/kind"; kind delete cluster' EXIT
          if ${with_all_features:-false}; then
               # Which DRA features exist can change over time.
               features=( $(grep '"DRA' pkg/features/kube_features.go | sed 's/.*"\(.*\)"/\1/') )
               echo "Enabling DRA feature(s): ${features[*]}."
               # Those additional features are not in kind.yaml, but they can be added at the end.
               kind create cluster --retain --config <(cat test/e2e/dra/kind.yaml; for feature in ${features}; do echo "  ${feature}: true"; done) --image dra/node:latest
               KUBERNETES_PROVIDER=local KUBECONFIG=${HOME}/.kube/config GINKGO_PARALLEL_NODES=8 E2E_REPORT_DIR=${ARTIFACTS} GINKGO_TIMEOUT=1h hack/ginkgo-e2e.sh -ginkgo.label-filter="Feature: containsAny DynamicResourceAllocation && Feature: isSubsetOf { Alpha, Beta, DynamicResourceAllocation$(for feature in ${features}; do echo , ${feature}; done)} && !Flaky && !Slow"
          else
              kind create cluster --retain --config test/e2e/dra/kind.yaml --image dra/node:latest
              KUBERNETES_PROVIDER=local KUBECONFIG=${HOME}/.kube/config GINKGO_PARALLEL_NODES=8 E2E_REPORT_DIR=${ARTIFACTS} GINKGO_TIMEOUT=2h30m hack/ginkgo-e2e.sh -ginkgo.label-filter='Feature: containsAny DynamicResourceAllocation && Feature: isSubsetOf { Beta, DynamicResourceAllocation } && !Flaky'
          fi

        # docker-in-docker needs privileged mode
        securityContext:
          privileged: true
        resources:
          limits:
            cpu: 2
            memory: 9Gi
          requests:
            cpu: 2
            memory: 9Gi

  - &e2e-node-job
    <<: *job
    labels:
      preset-service-account: "true"
      preset-k8s-ssh: "true"
    decoration_config:
      timeout: 90m
    spec:
      containers:
      - &e2e-node-container
        image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20241128-8df65c072f-master
        command:
        - /bin/bash
        - -ce
        - |
          export IGNITION_INJECT_GCE_SSH_PUBLIC_KEY_FILE=1
          export GOPATH=/go

          # Compose the command depending on the `runtime` variable set for the job.
          cmd=(
             runner.sh
             /workspace/scenarios/kubernetes_e2e.py
             --deployment=node
             --env=KUBE_SSH_USER=core
             --gcp-zone=us-west1-b
             --node-tests=true
             --provider=gce
             '--test_args=--timeout=1h --label-filter="Feature: containsAny DynamicResourceAllocation && Feature: isSubsetOf { Beta, DynamicResourceAllocation } && !Flaky"'
             --timeout=65m
          )
          case ${runtime:-containerd} in
              containerd)
                  cmd+=(
                      '--node-test-args=--feature-gates=DynamicResourceAllocation=true --service-feature-gates=DynamicResourceAllocation=true --runtime-config=api/beta=true --container-runtime-endpoint=unix:///run/containerd/containerd.sock --container-runtime-process-name=/usr/bin/containerd --container-runtime-pid-file= --kubelet-flags="--cgroup-driver=systemd --cgroups-per-qos=true --cgroup-root=/ --runtime-cgroups=/system.slice/containerd.service" --extra-log="{\"name\": \"containerd.log\", \"journalctl\": [\"-u\", \"containerd\"]}"'
                      --node-args=--image-config-file=/home/prow/go/src/k8s.io/test-infra/jobs/e2e_node/dra/image-config-containerd-1.7.yaml
                  )
                  ;;
              crio-cgroupv1)
                  cmd+=(
                      '--node-test-args=--feature-gates=DynamicResourceAllocation=true --service-feature-gates=DynamicResourceAllocation=true --runtime-config=api/beta=true --container-runtime-endpoint=unix:///var/run/crio/crio.sock --container-runtime-process-name=/usr/local/bin/crio --container-runtime-pid-file= --kubelet-flags="--cgroup-driver=systemd --cgroups-per-qos=true --cgroup-root=/ --runtime-cgroups=/system.slice/crio.service --kubelet-cgroups=/system.slice/kubelet.service" --extra-log="{\"name\": \"crio.log\", \"journalctl\": [\"-u\", \"crio\"]}"'
                      --node-args=--image-config-file=/home/prow/go/src/k8s.io/test-infra/jobs/e2e_node/crio/latest/image-config-cgroupv1-serial.yaml
                  )
                  ;;
              crio-cgroupv2)
                  cmd+=(
                      '--node-test-args=--feature-gates=DynamicResourceAllocation=true --service-feature-gates=DynamicResourceAllocation=true --runtime-config=api/beta=true --container-runtime-endpoint=unix:///var/run/crio/crio.sock --container-runtime-process-name=/usr/local/bin/crio --container-runtime-pid-file= --kubelet-flags="--cgroup-driver=systemd --cgroups-per-qos=true --cgroup-root=/ --runtime-cgroups=/system.slice/crio.service --kubelet-cgroups=/system.slice/kubelet.service" --extra-log="{\"name\": \"crio.log\", \"journalctl\": [\"-u\", \"crio\"]}"'
                      --node-args=--image-config-file=/home/prow/go/src/k8s.io/test-infra/jobs/e2e_node/crio/latest/image-config-cgroupv2-serial.yaml
                  )
                  ;;
          esac

          # Run it.
          set -x
          ${cmd[@]}

        resources:
          limits:
            cpu: 2
            memory: 9Gi
          requests:
            cpu: 2
            memory: 9Gi

periodics:

  - <<: *e2e-kind-job
    <<: *periodic-job
    name: ci-kind-dra-canary
    annotations:
      <<: *annotations
      testgrid-tab-name: ci-kind-dra-canary
      description: Runs E2E tests for Dynamic Resource Allocation beta features against a Kubernetes master cluster created with sigs.k8s.io/kind

  - <<: *e2e-kind-job
    <<: *periodic-job
    name: ci-kind-dra-all-canary
    annotations:
      <<: *annotations
      testgrid-tab-name: ci-kind-dra-all-canary
      description: Runs E2E tests for Dynamic Resource Allocation alpha and beta features against a Kubernetes master cluster created with sigs.k8s.io/kind
    spec:
      containers:
      - <<: *e2e-kind-container
        env:
        - name: with_all_features
          value: "true"

  - <<: *e2e-node-job
    <<: *periodic-node-job
    name: ci-node-e2e-cgrpv1-crio-dra-canary
    annotations:
      <<: *annotations
      testgrid-dashboards: sig-node-cri-o, sig-node-dynamic-resource-allocation
      testgrid-tab-name: ci-node-e2e-cgrpv1-crio-dra-canary
      description: Runs E2E node tests for Dynamic Resource Allocation beta features with CRI-O using cgroup v1
    spec:
      containers:
      - <<: *e2e-node-container
        env:
        - name: runtime
          value: crio-cgroupv1

  - <<: *e2e-node-job
    <<: *periodic-node-job
    name: ci-node-e2e-cgrpv2-crio-dra-canary
    annotations:
      <<: *annotations
      testgrid-dashboards: sig-node-cri-o, sig-node-dynamic-resource-allocation
      description: Runs E2E node tests for Dynamic Resource Allocation beta features with CRI-O using cgroup v2
      testgrid-tab-name: ci-node-e2e-cgrpv2-crio-dra-canary
    spec:
      containers:
      - <<: *e2e-node-container
        env:
        - name: runtime
          value: crio-cgroupv1

  - <<: *e2e-node-job
    <<: *periodic-node-job
    name: ci-node-e2e-containerd-dra-canary
    annotations:
      <<: *annotations
      description: Runs E2E node tests for Dynamic Resource Allocation beta features with CRI-O using cgroup v1
      testgrid-tab-name: ci-node-e2e-containerd-dra-canary
    spec:
      containers:
      - <<: *e2e-node-container
        env:
        - name: runtime
          value: containerd

presubmits:
  kubernetes/kubernetes:

    - <<: *e2e-kind-job
      <<: *presubmit-job
      name: pull-kubernetes-kind-dra-canary
      annotations:
        <<: *annotations
        testgrid-tab-name: pull-kubernetes-kind-dra-canary
        description: Runs E2E tests for Dynamic Resource Allocation beta features against a Kubernetes master cluster created with sigs.k8s.io/kind
      run_if_changed: &e2e-run-if-changed-e2e /(dra|dynamicresources|resourceclaim|deviceclass|resourceslice|resourceclaimtemplate|dynamic-resource-allocation|pkg/apis/resource|api/resource)/.*.go

    - <<: *e2e-kind-job
      <<: *presubmit-job
      name: pull-kubernetes-kind-dra-all-canary
      annotations:
        <<: *annotations
        testgrid-tab-name: pull-kubernetes-kind-dra-all-canary
        description: Runs E2E tests for Dynamic Resource Allocation alpha and beta features against a Kubernetes master cluster created with sigs.k8s.io/kind
      run_if_changed: *e2e-run-if-changed-e2e
      spec:
        containers:
        - <<: *e2e-kind-container
          env:
          - name: with_all_features
            value: "true"

    - <<: *e2e-node-job
      <<: *presubmit-job
      name: pull-kubernetes-node-e2e-cgrpv1-crio-dra-canary
      annotations:
        <<: *annotations
        testgrid-dashboards: sig-node-cri-o, sig-node-dynamic-resource-allocation
        testgrid-tab-name: pull-kubernetes-node-e2e-cgrpv1-crio-dra-canary
        description: Runs E2E node tests for Dynamic Resource Allocation beta features with CRI-O using cgroup v1
      # Automatically testing with one container runtime in one configuration is sufficient to detect basic problems in kubelet early.
      # CRI-O was picked because it was solid for testing so far.
      # Periodic variant: ci-node-e2e-crio-cgrpv1-dra
      run_if_changed: (/dra/|/dynamicresources/|/resourceclaim/|/deviceclass/|/resourceslice/|/resourceclaimtemplate/|/dynamic-resource-allocation/|/pkg/apis/resource/|/api/resource/|/test/e2e_node/dra_).*\.(go|yaml)
      spec:
        containers:
        - <<: *e2e-node-container
          env:
          - name: runtime
            value: crio-cgroupv1

    - <<: *e2e-node-job
      <<: *presubmit-job
      name: pull-kubernetes-node-e2e-cgrpv2-crio-dra-canary
      annotations:
        <<: *annotations
        testgrid-dashboards: sig-node-cri-o, sig-node-dynamic-resource-allocation
        description: Runs E2E node tests for Dynamic Resource Allocation beta features with CRI-O using cgroup v2
        testgrid-tab-name: pull-kubernetes-node-e2e-cgrpv2-crio-dra-canary
      spec:
        containers:
        - <<: *e2e-node-container
          env:
          - name: runtime
            value: crio-cgroupv2

    - <<: *e2e-node-job
      <<: *presubmit-job
      name: pull-kubernetes-node-e2e-containerd-dra-canary
      annotations:
        <<: *annotations
        description: Runs E2E node tests for Dynamic Resource Allocation beta features with containerd
        testgrid-tab-name: pull-kubernetes-node-e2e-containerd-dra-canary
      spec:
        containers:
        - <<: *e2e-node-container
          env:
          - name: runtime
            value: containerd
