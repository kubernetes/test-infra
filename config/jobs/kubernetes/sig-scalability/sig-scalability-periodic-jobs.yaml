periodics:
- name: ci-kubernetes-e2e-gce-node-throughput
  cluster: k8s-infra-prow-build
  tags:
  - "perfDashPrefix: docker-node-throughput"
  - "perfDashJobType: throughput"
  interval: 1h
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-node: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 60m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-node
    testgrid-tab-name: node-throughput
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20230330-8e9af88c7d-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --check-leaked-resources
      - --cluster=
      - --env=CONTAINER_IMAGE=registry-sandbox.k8s.io/pause:3.1 #TODO(ameukam): revert when registry.k8s.io is ready
      - --extract=ci/latest
      - --gcp-node-image=gci
      - --gcp-nodes=1
      - --provider=gce
      - --test=false
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=1
      - --test-cmd-args=--provider=gce
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testconfig=testing/node-throughput/config.yaml
      - --test-cmd-args=--testoverrides=./testing/overrides/node_docker.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=40m
      - --use-logexporter
      - --logexporter-gcs-path=gs://sig-scalability-logs/$(JOB_NAME)/$(BUILD_ID)
      resources:
        requests:
          cpu: 2
          memory: "6Gi"
        limits:
          cpu: 2
          memory: "6Gi"

- name: ci-kubernetes-e2e-gce-node-containerd-throughput
  cluster: k8s-infra-prow-build
  tags:
  - "perfDashPrefix: containerd-node-throughput"
  - "perfDashJobType: throughput"
  interval: 1h
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-node: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 60m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-node
    testgrid-tab-name: node-containerd-throughput
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20230330-8e9af88c7d-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --check-leaked-resources
      - --cluster=
      - --env=CONTAINER_IMAGE=registry-sandbox.k8s.io/pause:3.1 #TODO(ameukam): revert when registry.k8s.io is ready
      - --extract=ci/latest
      - --gcp-node-image=gci
      - --gcp-nodes=1
      - --provider=gce
      - --test=false
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=1
      - --test-cmd-args=--provider=gce
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testconfig=testing/node-throughput/config.yaml
      - --test-cmd-args=--testoverrides=./testing/overrides/node_containerd.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=40m
      - --use-logexporter
      - --logexporter-gcs-path=gs://sig-scalability-logs/$(JOB_NAME)/$(BUILD_ID)
      resources:
        requests:
          cpu: 2
          memory: "6Gi"
        limits:
          cpu: 2
          memory: "6Gi"

#kubemark
- name: ci-kubernetes-kubemark-100-gce
  tags:
  - "perfDashPrefix: kubemark-100Nodes"
  - "perfDashJobType: performance"
  interval: 3h
  cluster: k8s-infra-prow-build
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-dind-enabled: "true"
    preset-e2e-kubemark-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 260m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-alert-email: kubernetes-sig-scale@googlegroups.com, kubernetes-scalability-tickets@google.com
    testgrid-dashboards: sig-scalability-kubemark
    testgrid-tab-name: kubemark-100
    testgrid-num-failures-to-alert: '2'
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20230330-8e9af88c7d-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=kubemark-100
      - --extract=ci/latest
      - --gcp-master-size=n1-standard-2
      - --gcp-node-image=gci
      - --gcp-node-size=e2-standard-4
      - --gcp-nodes=4
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-east1-b
      - --kubemark
      - --kubemark-nodes=100
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      - --env=KUBEMARK_APISERVER_TEST_ARGS=--max-requests-inflight=80 --max-mutating-requests-inflight=0 --profiling --contention-profiling
      - --test=false
      - --test_args=--ginkgo.focus=xxxx
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=100
      - --test-cmd-args=--prometheus-scrape-node-exporter=true
      - --test-cmd-args=--provider=kubemark
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testconfig=testing/load/config.yaml
      - --test-cmd-args=--testconfig=testing/huge-service/config.yaml
      - --test-cmd-args=--testconfig=testing/access-tokens/config.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/enable_restart_count_check.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/use_simple_latency_query.yaml
      - --test-cmd-args=--testoverrides=./testing/overrides/kubemark_load_throughput.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=240m
      - --use-logexporter
      - --logexporter-gcs-path=gs://sig-scalability-logs/$(JOB_NAME)/$(BUILD_ID)
      # docker-in-docker needs privileged mode
      securityContext:
        privileged: true
      resources:
        requests:
          cpu: 2
          memory: "6Gi"
        limits:
          cpu: 2
          memory: "6Gi"

- name: ci-kubernetes-kubemark-100-gce-scheduler
  cluster: k8s-infra-prow-build
  tags:
  - "perfDashPrefix: kubemark-100Nodes-scheduler"
  - "perfDashJobType: performance"
  interval: 24h
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-dind-enabled: "true"
    preset-e2e-kubemark-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 170m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-kubemark
    testgrid-tab-name: kubemark-100-scheduler
    testgrid-num-failures-to-alert: '1'
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20230330-8e9af88c7d-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=kubemark-100
      - --extract=ci/latest
      - --gcp-master-size=n1-standard-2
      - --gcp-node-image=gci
      - --gcp-node-size=e2-standard-4
      - --gcp-nodes=4
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-east1-b
      - --kubemark
      - --kubemark-nodes=100
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      - --test=false
      - --test_args=--ginkgo.focus=xxxx
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=100
      - --test-cmd-args=--prometheus-scrape-node-exporter=true
      - --test-cmd-args=--provider=kubemark
      - --env=CL2_ENABLE_DNS_PROGRAMMING=true
      - --env=KUBEMARK_APISERVER_TEST_ARGS=--max-requests-inflight=80 --max-mutating-requests-inflight=0 --profiling --contention-profiling
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testsuite=testing/density/scheduler-suite.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/enable_restart_count_check.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/use_simple_latency_query.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=150m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      # docker-in-docker needs privileged mode
      securityContext:
        privileged: true
      resources:
        requests:
          cpu: 2
          memory: "2Gi"
        limits:
          cpu: 2
          memory: "2Gi"

- name: ci-kubernetes-kubemark-100-gce-scheduler-highqps
  tags:
  - "perfDashPrefix: kubemark-100Nodes-scheduler-highqps"
  - "perfDashJobType: performance"
  interval: 24h
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-dind-enabled: "true"
    preset-e2e-kubemark-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 170m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-kubemark
    testgrid-tab-name: kubemark-100-scheduler-highqps
    testgrid-num-failures-to-alert: '1'
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20230330-8e9af88c7d-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=kubemark-100-scheduler-highqps
      - --extract=ci/latest
      - --gcp-master-size=n1-standard-2
      - --gcp-node-image=gci
      - --gcp-node-size=e2-standard-4
      - --gcp-nodes=4
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-east1-b
      - --kubemark
      - --kubemark-nodes=100
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      - --env=KUBEMARK_APISERVER_TEST_ARGS=--max-requests-inflight=80 --max-mutating-requests-inflight=0 --profiling --contention-profiling
      - --env=CONTROLLER_MANAGER_TEST_ARGS=--profiling --contention-profiling --kube-api-qps=300 --kube-api-burst=300
      - --env=SCHEDULER_TEST_ARGS=--profiling --contention-profiling --kube-api-qps=300 --kube-api-burst=300
      - --env=CL2_ENABLE_CLUSTER_OOMS_TRACKER=true
      - --test=false
      - --test_args=--ginkgo.focus=xxxx
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=100
      - --test-cmd-args=--prometheus-scrape-node-exporter=true
      - --test-cmd-args=--provider=kubemark
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testsuite=testing/density/scheduler-suite.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/enable_restart_count_check.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/use_simple_latency_query.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=150m
      - --use-logexporter
      - --logexporter-gcs-path=gs://sig-scalability-logs/$(JOB_NAME)/$(BUILD_ID)
      # docker-in-docker needs privileged mode
      securityContext:
        privileged: true
      resources:
        requests:
          cpu: 2
          memory: "2Gi"
        limits:
          cpu: 2
          memory: "2Gi"

- name: ci-kubernetes-kubemark-500-gce
  cluster: k8s-infra-prow-build
  tags:
  - "perfDashPrefix: kubemark-500Nodes"
  - "perfDashJobType: performance"
  interval: 1h
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-dind-enabled: "true"
    preset-e2e-kubemark-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 120m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    fork-per-release: "true"
    fork-per-release-cron: 0 3 * * *, 0 7 * * *, 0 13 * * *, 0 17 * * *, 0 21 * * *
    fork-per-release-deletions: "preset-e2e-scalability-periodics-master"
    fork-per-release-replacements: "kubemark-500Nodes -> kubemark-500Nodes-{{.Version}}, extract=ci/latest -> extract=ci/latest-{{.Version}}, gcp-project=k8s-jenkins-blocking-kubemark -> gcp-project-type=scalability-project, us-central1-f -> us-east1-b"
    testgrid-alert-email: kubernetes-sig-scale@googlegroups.com, kubernetes-scalability-tickets@google.com
    testgrid-dashboards: sig-scalability-kubemark
    testgrid-tab-name: kubemark-master-500
    testgrid-num-failures-to-alert: '2'
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20230330-8e9af88c7d-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=kubemark-500
      - --extract=ci/latest
      - --gcp-master-size=n1-standard-4
      - --gcp-node-image=gci
      - --gcp-node-size=e2-standard-8
      - --gcp-nodes=8
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-central1-f
      - --kubemark
      - --kubemark-nodes=500
      - --metadata-sources=cl2-metadata.json
      - --env=KUBEMARK_APISERVER_TEST_ARGS=--max-requests-inflight=160 --max-mutating-requests-inflight=0 --profiling --contention-profiling
      - --provider=gce
      - --test=false
      - --test_args=--ginkgo.focus=xxxx
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=500
      - --test-cmd-args=--provider=kubemark
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testconfig=testing/load/config.yaml
      - --test-cmd-args=--testconfig=testing/huge-service/config.yaml
      - --test-cmd-args=--testconfig=testing/access-tokens/config.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/use_simple_latency_query.yaml
      - --test-cmd-args=--testoverrides=./testing/overrides/kubemark_500_nodes.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=100m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      # docker-in-docker needs privilged mode
      securityContext:
        privileged: true
      resources:
        requests:
          cpu: 2
          memory: "8Gi"
        limits:
          cpu: 2
          memory: "8Gi"

- name: ci-kubernetes-kubemark-gce-scale
  cluster: k8s-infra-prow-build
  tags:
  - "perfDashPrefix: kubemark-5000Nodes"
  - "perfDashJobType: performance"
  # For cost-efficiency reasons, we're switching this job off,
  # by setting it to run on February 31st.
  cron: '0 0 31 2 *'
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-dind-enabled: "true"
    preset-e2e-kubemark-common: "true"
    preset-e2e-kubemark-gce-scale: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 1100m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-alert-email: kubernetes-sig-scale@googlegroups.com, kubernetes-scalability-tickets@google.com
    testgrid-dashboards: sig-scalability-kubemark
    testgrid-tab-name: kubemark-5000
    testgrid-num-failures-to-alert: '2'
    testgrid-num-columns-recent: '3'
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20230330-8e9af88c7d-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=kubemark-5000
      - --extract=ci/latest
      - --gcp-node-image=gci
      - --gcp-node-size=e2-standard-8
      - --gcp-nodes=84
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-east1-b
      - --kubemark
      - --kubemark-nodes=5000
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      # With APF only sum of --max-requests-inflight and --max-mutating-requests-inflight matters, so set --max-mutating-requests-inflight to 0.
      - --env=KUBEMARK_APISERVER_TEST_ARGS=--max-requests-inflight=640 --max-mutating-requests-inflight=0 --profiling --contention-profiling
      - --test=false
      - --test_args=--ginkgo.focus=xxxx
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--experimental-gcp-snapshot-prometheus-disk=true
      - --test-cmd-args=--experimental-prometheus-disk-snapshot-name=$(JOB_NAME)-$(BUILD_ID)
      - --test-cmd-args=--experimental-prometheus-snapshot-to-report-dir=true
      - --test-cmd-args=--nodes=5000
      - --test-cmd-args=--provider=kubemark
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testconfig=testing/load/config.yaml
      - --test-cmd-args=--testconfig=testing/huge-service/config.yaml
      - --test-cmd-args=--testconfig=testing/access-tokens/config.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/enable_restart_count_check.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/ignore_known_kubemark_container_restarts.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=1080m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      # docker-in-docker needs privilged mode
      securityContext:
        privileged: true
      resources:
        requests:
          cpu: 6
          memory: "16Gi"
        limits:
          cpu: 6
          memory: "16Gi"

- name: ci-kubernetes-kubemark-gce-scale-scheduler
  cluster: k8s-infra-prow-build
  tags:
  - "perfDashPrefix: kubemark-5000Nodes-scheduler"
  - "perfDashJobType: performance"
  # Run at 10:01 UTC on the even days of each month. There will be ample time
  # between the kubemark-5000Nodes job (expected to start at 16:01 UTC the
  # previous day and finish in around ~12-14 hours) and this job. This job is
  # expected to take ~6-8 hours, which should allow it to finish well before
  # the next kubemark-5000Nodes job (at 00:01 UTC).
  cron: '1 10 2-31/2 * *'
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-dind-enabled: "true"
    preset-e2e-kubemark-common: "true"
    preset-e2e-kubemark-gce-scale: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 1100m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-kubemark
    testgrid-tab-name: kubemark-5000-scheduler
    testgrid-num-failures-to-alert: '1'
    testgrid-num-columns-recent: '3'
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20230330-8e9af88c7d-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=kubemark-5000
      - --extract=ci/latest
      - --gcp-node-image=gci
      - --gcp-node-size=e2-standard-8
      - --gcp-nodes=84
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-east1-b
      - --kubemark
      - --kubemark-nodes=5000
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      - --test=false
      - --test_args=--ginkgo.focus=xxxx
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--experimental-gcp-snapshot-prometheus-disk=true
      - --test-cmd-args=--experimental-prometheus-disk-snapshot-name=$(JOB_NAME)-$(BUILD_ID)
      - --test-cmd-args=--experimental-prometheus-snapshot-to-report-dir=true
      - --test-cmd-args=--nodes=5000
      - --test-cmd-args=--provider=kubemark
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testsuite=testing/density/scheduler-suite.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/enable_restart_count_check.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/ignore_known_kubemark_container_restarts.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=1080m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      # docker-in-docker needs privilged mode
      securityContext:
        privileged: true
      resources:
        limits:
          cpu: 6
          memory: "16Gi"
        requests:
          cpu: 6
          memory: "16Gi"

- name: ci-kubernetes-kubemark-high-density-100-gce
  cluster: k8s-infra-prow-build
  tags:
  - "perfDashPrefix: kubemark-100Nodes-highDensity"
  - "perfDashJobType: performance"
  interval: 24h
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-dind-enabled: "true"
    preset-e2e-kubemark-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 300m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-kubemark
    testgrid-tab-name: kubemark-100-high-density
    testgrid-num-failures-to-alert: '1'
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20230330-8e9af88c7d-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=kubemark-100pods
      - --extract=ci/latest
      - --gcp-node-image=gci
      - --gcp-node-size=e2-standard-8
      - --gcp-nodes=9
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-east1-b
      - --kubemark
      - --kubemark-master-size=n1-standard-32
      - --kubemark-nodes=600
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      - --env=KUBEMARK_APISERVER_TEST_ARGS=--max-requests-inflight=80 --max-mutating-requests-inflight=0 --profiling --contention-profiling
      - --test=false
      - --test_args=--ginkgo.focus=xxxx
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=600
      - --test-cmd-args=--provider=kubemark
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      # TODO(https://github.com/kubernetes/perf-tests/issues/1007): load test should be used to test high-density.
      - --test-cmd-args=--testconfig=testing/density/high-density-config.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/use_simple_latency_query.yaml
      - --test-cmd-args=--testoverrides=./testing/overrides/600_nodes_high_density.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=280m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      # docker-in-docker needs privileged mode
      securityContext:
        privileged: true
      resources:
        requests:
          cpu: 2
          memory: "8Gi"
        limits:
          cpu: 2
          memory: "8Gi"

- name: ci-perf-tests-kubemark-100-benchmark
  cluster: k8s-infra-prow-build
  interval: 2h
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 10m
  extra_refs:
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-perf-tests
    testgrid-tab-name: kubemark-100-benchmark
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20230330-8e9af88c7d-master
      command:
      - runner.sh
      args:
      - ./benchmark/runner.sh
      resources:
        requests:
          cpu: 1
          memory: "2Gi"
        limits:
          cpu: 1
          memory: "2Gi"

- name: ci-benchmark-scheduler-perf-master
  cluster: k8s-infra-prow-build
  tags:
  - "perfDashPrefix: scheduler-perf-benchmark"
  - "perfDashJobType: benchmark"
  interval: 2h30m
  annotations:
    testgrid-dashboards: sig-scalability-benchmarks
    testgrid-tab-name: scheduler-perf
  decorate: true
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  decoration_config:
    timeout: 2h25m
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20230330-8e9af88c7d-master
      command:
      - ./hack/jenkins/benchmark-dockerized.sh
      args:
      - ./test/integration/scheduler_perf
      env:
      - name: KUBE_TIMEOUT
        value: --timeout=2h25m
      - name: TEST_PREFIX
        value: BenchmarkPerfScheduling
      # Set the benchtime to a very low value so every test is ran at most once
      # even on very powerful machines
      - name: BENCHTIME
        value: 1ns
      # We need to constraint compute resources so all the tests
      # finish approximately at the same time. More compute power
      # can increase scheduling throughput and make consequent results
      # incomparable.
      resources:
        requests:
          cpu: 6
          memory: "24Gi"
        limits:
          cpu: 6
          memory: "24Gi"

- name: ci-benchmark-kube-dns-master
  cluster: k8s-infra-prow-build
  interval: 2h
  tags:
  - "perfDashPrefix: kube-dns benchmark"
  - "perfDashJobType: dnsBenchmark"
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 140m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-benchmarks
    testgrid-tab-name: kube-dns
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20230330-8e9af88c7d-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --check-leaked-resources
      - --cluster=kube-dns-benchmark
      - --extract=ci/latest
      - --gcp-node-size=e2-standard-2
      - --gcp-nodes=3
      - --gcp-zone=us-east1-b
      - --provider=gce
      - --test=false
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=kube-dns
      - --test-cmd-args=$(ARTIFACTS)/out
      - --test-cmd-args=$(ARTIFACTS)
      - --test-cmd-name=KubeDnsBenchmark
      - --timeout=120m
      resources:
        requests:
          cpu: 2
          memory: "6Gi"
        limits:
          cpu: 2
          memory: "6Gi"

- name: ci-benchmark-nodelocal-dns-master
  cluster: k8s-infra-prow-build
  interval: 2h
  tags:
  - "perfDashPrefix: node-local-dns benchmark"
  - "perfDashJobType: dnsBenchmark"
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 140m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-benchmarks
    testgrid-tab-name: node-local-dns
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20230330-8e9af88c7d-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --check-leaked-resources
      - --cluster=node-local-dns-benchmark
      - --env=KUBE_ENABLE_NODELOCAL_DNS=true
      - --extract=ci/latest
      - --gcp-node-size=e2-standard-2
      - --gcp-nodes=3
      - --gcp-zone=us-east1-b
      - --provider=gce
      - --test=false
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=node-local-dns
      - --test-cmd-args=$(ARTIFACTS)/out
      - --test-cmd-args=$(ARTIFACTS)
      - --test-cmd-args=169.254.20.10
      - --test-cmd-name=KubeDnsBenchmark
      - --timeout=120m
      resources:
        requests:
          cpu: 2
          memory: "4Gi"
        limits:
          cpu: 2
          memory: "4Gi"

- name: ci-kubernetes-e2e-gce-network-metric-measurement
  cluster: k8s-infra-prow-build
  tags:
    - "perfDashPrefix: network-performance"
    - "perfDashJobType: performance"
  interval: 24h
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  annotations:
    testgrid-dashboards: sig-scalability-network
    testgrid-tab-name: metric-measurement
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20230330-8e9af88c7d-master
      args:
      - --repo=k8s.io/kubernetes=master
      - --repo=k8s.io/perf-tests=master
      - --root=/go/src
      - --timeout=60
      - --scenario=kubernetes_e2e
      - --
      - --check-leaked-resources
      - --cluster=
      - --extract=ci/latest
      - --gcp-node-image=gci
      - --gcp-nodes=102
      - --provider=gce
      - --test=false
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=100
      - --test-cmd-args=--provider=gce
      - --test-cmd-args=--report-dir=/workspace/_artifacts
      - --test-cmd-args=--testsuite=testing/network/suite.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=40m
      - --use-logexporter
      resources:
        requests:
          cpu: 1
          memory: "2Gi"
        limits:
          cpu: 1
          memory: "2Gi"

- interval: 12h
  cluster: k8s-infra-prow-build
  name: ci-kubernetes-e2e-gci-gce-benchmark-requests-1
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 60m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-benchmarks
    testgrid-tab-name: gce-benchmark-requests-1
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20230330-8e9af88c7d-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --check-leaked-resources
      - --cluster=benchmark-small
      # Eliminate test flakiness
      - --env=ALLOWED_NOTREADY_NODES=1
      - --env=APISERVER_TEST_ARGS=--max-requests-inflight=1000 --max-mutating-requests-inflight=0 --profiling --contention-profiling
      - --env=CL2_BENCHMARK_INFLIGHT=1
      - --env=CL2_BENCHMARK_URI=/api/v1/namespaces/%namespace%/configmaps/benchmark-config-map-0?resourceVersion=0
      - --extract=ci/latest
      - --gcp-master-size=n1-standard-96
      - --gcp-node-image=gci
      - --gcp-node-size=e2-standard-8
      - --gcp-nodes=1
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-east1-b
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      - --test=false
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--experimental-gcp-snapshot-prometheus-disk=true
      - --test-cmd-args=--experimental-prometheus-disk-snapshot-name=$(JOB_NAME)-$(BUILD_ID)
      - --test-cmd-args=--experimental-prometheus-snapshot-to-report-dir=true
      - --test-cmd-args=--nodes=1
      - --test-cmd-args=--prometheus-scrape-kubelets=true
      - --test-cmd-args=--prometheus-scrape-node-exporter
      - --test-cmd-args=--provider=gce
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testconfig=testing/request-benchmark/config.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=45m
      - --use-logexporter
      - --logexporter-gcs-path=gs://sig-scalability-logs/$(JOB_NAME)/$(BUILD_ID)
      resources:
        requests:
          cpu: 2
          memory: 6Gi
        limits:
          cpu: 2
          memory: 6Gi
