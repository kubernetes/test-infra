periodics:
- name: ci-kubernetes-e2e-gce-node-throughput
  cluster: k8s-infra-prow-build
  tags:
  - "perfDashPrefix: docker-node-throughput"
  - "perfDashJobType: throughput"
  interval: 1h
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-node: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 60m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-node
    testgrid-tab-name: node-throughput
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --check-leaked-resources
      - --cluster=
      - --env=CONTAINER_IMAGE=registry-sandbox.k8s.io/pause:3.1 #TODO(ameukam): revert when registry.k8s.io is ready
      - --extract=ci/latest
      - --gcp-node-image=gci
      - --gcp-nodes=1
      - --provider=gce
      - --test=false
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=1
      - --test-cmd-args=--provider=gce
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testconfig=testing/node-throughput/config.yaml
      - --test-cmd-args=--testoverrides=./testing/overrides/node_docker.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=40m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      resources:
        requests:
          cpu: 2
          memory: "6Gi"
        limits:
          cpu: 2
          memory: "6Gi"

- name: ci-kubernetes-e2e-gce-node-containerd-throughput
  cluster: k8s-infra-prow-build
  tags:
  - "perfDashPrefix: containerd-node-throughput"
  - "perfDashJobType: throughput"
  interval: 1h
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-node: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 60m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-node
    testgrid-tab-name: node-containerd-throughput
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --check-leaked-resources
      - --cluster=
      - --env=CONTAINER_IMAGE=registry-sandbox.k8s.io/pause:3.1 #TODO(ameukam): revert when registry.k8s.io is ready
      - --extract=ci/latest
      - --gcp-node-image=gci
      - --gcp-nodes=1
      - --provider=gce
      - --test=false
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=1
      - --test-cmd-args=--provider=gce
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testconfig=testing/node-throughput/config.yaml
      - --test-cmd-args=--testoverrides=./testing/overrides/node_containerd.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=40m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      resources:
        requests:
          cpu: 2
          memory: "6Gi"
        limits:
          cpu: 2
          memory: "6Gi"

#kubemark
- name: ci-kubernetes-kubemark-100-gce
  tags:
  - "perfDashPrefix: kubemark-100Nodes"
  - "perfDashJobType: performance"
  interval: 3h
  cluster: k8s-infra-prow-build
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-dind-enabled: "true"
    preset-e2e-kubemark-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 260m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-alert-email: kubernetes-sig-scale@googlegroups.com, kubernetes-scalability-tickets@google.com
    testgrid-dashboards: sig-scalability-kubemark
    testgrid-tab-name: kubemark-100
    testgrid-num-failures-to-alert: '2'
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=kubemark-100
      - --extract=ci/latest
      - --gcp-master-size=n2-standard-2
      - --gcp-node-image=gci
      - --gcp-node-size=e2-standard-4
      - --gcp-nodes=4
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-east1-b
      - --kubemark
      - --kubemark-nodes=100
      - --kubemark-master-size=n2-standard-8
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      - --env=KUBEMARK_APISERVER_TEST_ARGS=--max-requests-inflight=80 --max-mutating-requests-inflight=0 --profiling --contention-profiling
      - --test=false
      - --test_args=--ginkgo.focus=xxxx
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=100
      - --test-cmd-args=--prometheus-scrape-node-exporter=true
      - --test-cmd-args=--provider=kubemark
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testconfig=testing/load/config.yaml
      - --test-cmd-args=--testconfig=testing/huge-service/config.yaml
      - --test-cmd-args=--testconfig=testing/access-tokens/config.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/enable_restart_count_check.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/use_simple_latency_query.yaml
      - --test-cmd-args=--testoverrides=./testing/overrides/kubemark_load_throughput.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=240m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      # docker-in-docker needs privileged mode
      securityContext:
        privileged: true
      resources:
        requests:
          cpu: 2
          memory: "6Gi"
        limits:
          cpu: 2
          memory: "6Gi"

- name: ci-kubernetes-kubemark-100-gce-scheduler
  cluster: k8s-infra-prow-build
  tags:
  - "perfDashPrefix: kubemark-100Nodes-scheduler"
  - "perfDashJobType: performance"
  interval: 24h
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-dind-enabled: "true"
    preset-e2e-kubemark-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 170m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-kubemark
    testgrid-tab-name: kubemark-100-scheduler
    testgrid-num-failures-to-alert: '1'
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=kubemark-100
      - --extract=ci/latest
      - --gcp-master-size=n2-standard-2
      - --gcp-node-image=gci
      - --gcp-node-size=e2-standard-4
      - --gcp-nodes=4
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-east1-b
      - --kubemark
      - --kubemark-nodes=100
      - --kubemark-master-size=n2-standard-8
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      - --test=false
      - --test_args=--ginkgo.focus=xxxx
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=100
      - --test-cmd-args=--prometheus-scrape-node-exporter=true
      - --test-cmd-args=--provider=kubemark
      - --env=CL2_ENABLE_DNS_PROGRAMMING=true
      - --env=KUBEMARK_APISERVER_TEST_ARGS=--max-requests-inflight=80 --max-mutating-requests-inflight=0 --profiling --contention-profiling
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testsuite=testing/density/scheduler-suite.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/enable_restart_count_check.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/use_simple_latency_query.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=150m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      # docker-in-docker needs privileged mode
      securityContext:
        privileged: true
      resources:
        requests:
          cpu: 2
          memory: "6Gi"
        limits:
          cpu: 2
          memory: "6Gi"

- name: ci-kubernetes-kubemark-100-gce-scheduler-highqps
  cluster: k8s-infra-prow-build
  tags:
  - "perfDashPrefix: kubemark-100Nodes-scheduler-highqps"
  - "perfDashJobType: performance"
  interval: 24h
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-dind-enabled: "true"
    preset-e2e-kubemark-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 170m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-kubemark
    testgrid-tab-name: kubemark-100-scheduler-highqps
    testgrid-num-failures-to-alert: '1'
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=kubemark-100-scheduler-highqps
      - --extract=ci/latest
      - --gcp-master-size=n2-standard-2
      - --gcp-node-image=gci
      - --gcp-node-size=e2-standard-4
      - --gcp-nodes=4
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-east1-b
      - --kubemark
      - --kubemark-nodes=100
      - --kubemark-master-size=n2-standard-8
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      - --env=KUBEMARK_APISERVER_TEST_ARGS=--max-requests-inflight=80 --max-mutating-requests-inflight=0 --profiling --contention-profiling
      - --env=CONTROLLER_MANAGER_TEST_ARGS=--authorization-always-allow-paths=/healthz,/readyz,/livez,/metrics --profiling --contention-profiling --kube-api-qps=300 --kube-api-burst=300
      - --env=SCHEDULER_TEST_ARGS=--authorization-always-allow-paths=/healthz,/readyz,/livez,/metrics --profiling --contention-profiling --kube-api-qps=300 --kube-api-burst=300
      - --env=CL2_ENABLE_CLUSTER_OOMS_TRACKER=true
      - --test=false
      - --test_args=--ginkgo.focus=xxxx
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=100
      - --test-cmd-args=--prometheus-scrape-node-exporter=true
      - --test-cmd-args=--provider=kubemark
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testsuite=testing/density/scheduler-suite.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/enable_restart_count_check.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/use_simple_latency_query.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=150m
      # docker-in-docker needs privileged mode
      securityContext:
        privileged: true
      resources:
        requests:
          cpu: 2
          memory: "6Gi"
        limits:
          cpu: 2
          memory: "6Gi"

- name: ci-kubernetes-kubemark-500-gce
  cluster: k8s-infra-prow-build
  tags:
  - "perfDashPrefix: kubemark-500Nodes"
  - "perfDashJobType: performance"
  interval: 1h
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-dind-enabled: "true"
    preset-e2e-kubemark-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 120m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    fork-per-release: "true"
    fork-per-release-cron: 0 3 * * *, 0 7 * * *, 0 13 * * *, 0 17 * * *, 0 21 * * *
    fork-per-release-deletions: "preset-e2e-scalability-periodics-master"
    fork-per-release-replacements: "kubemark-500Nodes -> kubemark-500Nodes-{{.Version}}, extract=ci/latest -> extract=ci/latest-{{.Version}}, gcp-project=k8s-jenkins-blocking-kubemark -> gcp-project-type=scalability-project, us-central1-f -> us-east1-b"
    testgrid-alert-email: kubernetes-sig-scale@googlegroups.com, kubernetes-scalability-tickets@google.com
    testgrid-dashboards: sig-scalability-kubemark
    testgrid-tab-name: kubemark-master-500
    testgrid-num-failures-to-alert: '2'
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=kubemark-500
      - --extract=ci/latest
      - --gcp-master-size=n2-standard-4
      - --gcp-node-image=gci
      - --gcp-node-size=e2-standard-8
      - --gcp-nodes=8
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-central1-f
      - --kubemark
      - --kubemark-nodes=500
      - --kubemark-master-size=n2-standard-16
      - --metadata-sources=cl2-metadata.json
      - --env=KUBEMARK_APISERVER_TEST_ARGS=--max-requests-inflight=160 --max-mutating-requests-inflight=0 --profiling --contention-profiling
      - --provider=gce
      - --test=false
      - --test_args=--ginkgo.focus=xxxx
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=500
      - --test-cmd-args=--provider=kubemark
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testconfig=testing/load/config.yaml
      - --test-cmd-args=--testconfig=testing/huge-service/config.yaml
      - --test-cmd-args=--testconfig=testing/access-tokens/config.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/use_simple_latency_query.yaml
      - --test-cmd-args=--testoverrides=./testing/overrides/kubemark_500_nodes.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=100m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      # docker-in-docker needs privilged mode
      securityContext:
        privileged: true
      resources:
        requests:
          cpu: 2
          memory: "8Gi"
        limits:
          cpu: 2
          memory: "8Gi"

- name: ci-kubernetes-kubemark-gce-scale
  cluster: k8s-infra-prow-build
  tags:
  - "perfDashPrefix: kubemark-5000Nodes"
  - "perfDashJobType: performance"
  # For cost-efficiency reasons, we're switching this job off,
  # by setting it to run on February 31st.
  cron: '0 0 31 2 *'
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-dind-enabled: "true"
    preset-e2e-kubemark-common: "true"
    preset-e2e-kubemark-gce-scale: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 1100m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-alert-email: kubernetes-sig-scale@googlegroups.com, kubernetes-scalability-tickets@google.com
    testgrid-dashboards: sig-scalability-kubemark
    testgrid-tab-name: kubemark-5000
    testgrid-num-failures-to-alert: '2'
    testgrid-num-columns-recent: '3'
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=kubemark-5000
      - --extract=ci/latest
      - --gcp-node-image=gci
      - --gcp-node-size=e2-standard-8
      - --gcp-master-size=n2-standard-64
      - --gcp-nodes=84
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-east1-b
      - --kubemark
      - --kubemark-nodes=5000
      - --kubemark-master-size=n2-standard-64
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      # With APF only sum of --max-requests-inflight and --max-mutating-requests-inflight matters, so set --max-mutating-requests-inflight to 0.
      - --env=KUBEMARK_APISERVER_TEST_ARGS=--max-requests-inflight=640 --max-mutating-requests-inflight=0 --profiling --contention-profiling
      - --test=false
      - --test_args=--ginkgo.focus=xxxx
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--experimental-gcp-snapshot-prometheus-disk=true
      - --test-cmd-args=--experimental-prometheus-disk-snapshot-name=$(JOB_NAME)-$(BUILD_ID)
      - --test-cmd-args=--experimental-prometheus-snapshot-to-report-dir=true
      - --test-cmd-args=--nodes=5000
      - --test-cmd-args=--provider=kubemark
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testconfig=testing/load/config.yaml
      - --test-cmd-args=--testconfig=testing/huge-service/config.yaml
      - --test-cmd-args=--testconfig=testing/access-tokens/config.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/enable_restart_count_check.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/ignore_known_kubemark_container_restarts.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=1080m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      # docker-in-docker needs privilged mode
      securityContext:
        privileged: true
      resources:
        requests:
          cpu: 6
          memory: "16Gi"
        limits:
          cpu: 6
          memory: "16Gi"

- name: ci-kubernetes-kubemark-gce-scale-scheduler
  cluster: k8s-infra-prow-build
  tags:
  - "perfDashPrefix: kubemark-5000Nodes-scheduler"
  - "perfDashJobType: performance"
  # Run at 10:01 UTC on the even days of each month. There will be ample time
  # between the kubemark-5000Nodes job (expected to start at 16:01 UTC the
  # previous day and finish in around ~12-14 hours) and this job. This job is
  # expected to take ~6-8 hours, which should allow it to finish well before
  # the next kubemark-5000Nodes job (at 00:01 UTC).
  cron: '1 10 2-31/2 * *'
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-dind-enabled: "true"
    preset-e2e-kubemark-common: "true"
    preset-e2e-kubemark-gce-scale: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 1100m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-kubemark
    testgrid-tab-name: kubemark-5000-scheduler
    testgrid-num-failures-to-alert: '1'
    testgrid-num-columns-recent: '3'
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=kubemark-5000
      - --extract=ci/latest
      - --gcp-node-image=gci
      - --gcp-node-size=e2-standard-8
      - --gcp-master-size=n2-standard-2
      - --gcp-nodes=84
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-east1-b
      - --kubemark
      - --kubemark-nodes=5000
      - --kubemark-master-size=n2-standard-64
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      - --test=false
      - --test_args=--ginkgo.focus=xxxx
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--experimental-gcp-snapshot-prometheus-disk=true
      - --test-cmd-args=--experimental-prometheus-disk-snapshot-name=$(JOB_NAME)-$(BUILD_ID)
      - --test-cmd-args=--experimental-prometheus-snapshot-to-report-dir=true
      - --test-cmd-args=--nodes=5000
      - --test-cmd-args=--provider=kubemark
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testsuite=testing/density/scheduler-suite.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/enable_restart_count_check.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/ignore_known_kubemark_container_restarts.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=1080m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      # docker-in-docker needs privilged mode
      securityContext:
        privileged: true
      resources:
        limits:
          cpu: 6
          memory: "16Gi"
        requests:
          cpu: 6
          memory: "16Gi"

- name: ci-kubernetes-kubemark-high-density-100-gce
  cluster: k8s-infra-prow-build
  tags:
  - "perfDashPrefix: kubemark-100Nodes-highDensity"
  - "perfDashJobType: performance"
  interval: 24h
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-dind-enabled: "true"
    preset-e2e-kubemark-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 300m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-kubemark
    testgrid-tab-name: kubemark-100-high-density
    testgrid-num-failures-to-alert: '1'
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=kubemark-100pods
      - --extract=ci/latest
      - --gcp-node-image=gci
      - --gcp-node-size=e2-standard-8
      - --gcp-master-size=n2-standard-2
      - --gcp-nodes=9
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-east1-b
      - --kubemark
      - --kubemark-master-size=n2-standard-32
      - --kubemark-nodes=600
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      - --env=KUBEMARK_APISERVER_TEST_ARGS=--max-requests-inflight=80 --max-mutating-requests-inflight=0 --profiling --contention-profiling
      - --test=false
      - --test_args=--ginkgo.focus=xxxx
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=600
      - --test-cmd-args=--provider=kubemark
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      # TODO(https://github.com/kubernetes/perf-tests/issues/1007): load test should be used to test high-density.
      - --test-cmd-args=--testconfig=testing/density/high-density-config.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/use_simple_latency_query.yaml
      - --test-cmd-args=--testoverrides=./testing/overrides/600_nodes_high_density.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=280m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      # docker-in-docker needs privileged mode
      securityContext:
        privileged: true
      resources:
        requests:
          cpu: 2
          memory: "8Gi"
        limits:
          cpu: 2
          memory: "8Gi"

- name: ci-perf-tests-kubemark-100-benchmark
  cluster: k8s-infra-prow-build
  interval: 2h
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 10m
  extra_refs:
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-perf-tests
    testgrid-tab-name: kubemark-100-benchmark
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      command:
      - runner.sh
      args:
      - ./benchmark/runner.sh
      resources:
        requests:
          cpu: 1
          memory: "2Gi"
        limits:
          cpu: 1
          memory: "2Gi"

# Note: we have a presubmit job "pull-kubernetes-scheduler-perf",
# which you likely want to change when you change parameters in this test.
- name: ci-benchmark-scheduler-perf-master
  cluster: k8s-infra-prow-build
  tags:
  - "perfDashPrefix: scheduler-perf-benchmark"
  - "perfDashJobType: benchmark"
  interval: 4h
  annotations:
    testgrid-dashboards: sig-scalability-benchmarks
    testgrid-tab-name: scheduler-perf
    testgrid-alert-email: sig-scheduling-alerts@kubernetes.io
  decorate: true
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  decoration_config:
    timeout: 3h55m
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      command:
      - ./hack/jenkins/benchmark-dockerized.sh
      args:
      - ./test/integration/scheduler_perf/...
      env:
      - name: KUBE_CACHE_MUTATION_DETECTOR
        value: "false"
      - name: KUBE_TIMEOUT
        value: --timeout=3h55m
      # Keep the unprocessed `go test` JSON output for debugging.
      - name: KUBE_KEEP_VERBOSE_TEST_OUTPUT
        value: "y"
      - name: TEST_PREFIX
        value: BenchmarkPerfScheduling
      # Set the benchtime to a very low value so every test is ran at most once
      # even on very powerful machines
      - name: BENCHTIME
        value: 1ns
      # We distinguish which test cases to run with --short, and we want to run longer test cases in this job.
      # We have to explicitly disable --short flag because the script enables by default.
      - name: SHORT
        value: --short=false
      # Capture success/failure and duration for each individual test case instead
      # of reducing everything at the package level.
      - name: KUBE_PRUNE_JUNIT_TESTS
        value: "false"
      # We need to constraint compute resources so all the tests
      # finish approximately at the same time. More compute power
      # can increase scheduling throughput and make consequent results
      # incomparable.
      resources:
        requests:
          cpu: 6
          memory: "24Gi"
        limits:
          cpu: 6
          memory: "24Gi"

- name: ci-benchmark-kube-dns-master
  cluster: k8s-infra-prow-build
  interval: 2h
  tags:
  - "perfDashPrefix: kube-dns benchmark"
  - "perfDashJobType: dnsBenchmark"
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 140m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-benchmarks
    testgrid-tab-name: kube-dns
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --check-leaked-resources
      - --cluster=kube-dns-benchmark
      - --extract=ci/latest
      - --gcp-node-size=e2-standard-2
      - --gcp-nodes=3
      - --gcp-zone=us-east1-b
      - --provider=gce
      - --test=false
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=kube-dns
      - --test-cmd-args=$(ARTIFACTS)/out
      - --test-cmd-args=$(ARTIFACTS)
      - --test-cmd-name=KubeDnsBenchmark
      - --timeout=120m
      resources:
        requests:
          cpu: 2
          memory: "6Gi"
        limits:
          cpu: 2
          memory: "6Gi"

- name: ci-benchmark-nodelocal-dns-master
  cluster: k8s-infra-prow-build
  interval: 2h
  tags:
  - "perfDashPrefix: node-local-dns benchmark"
  - "perfDashJobType: dnsBenchmark"
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 140m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-benchmarks
    testgrid-tab-name: node-local-dns
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --check-leaked-resources
      - --cluster=node-local-dns-benchmark
      - --env=KUBE_ENABLE_NODELOCAL_DNS=true
      - --extract=ci/latest
      - --gcp-node-size=e2-standard-2
      - --gcp-nodes=3
      - --gcp-zone=us-east1-b
      - --provider=gce
      - --test=false
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=node-local-dns
      - --test-cmd-args=$(ARTIFACTS)/out
      - --test-cmd-args=$(ARTIFACTS)
      - --test-cmd-args=169.254.20.10
      - --test-cmd-name=KubeDnsBenchmark
      - --timeout=120m
      resources:
        requests:
          cpu: 2
          memory: "4Gi"
        limits:
          cpu: 2
          memory: "4Gi"

- name: ci-kubernetes-e2e-gce-network-metric-measurement
  cluster: k8s-infra-prow-build
  tags:
    - "perfDashPrefix: network-performance"
    - "perfDashJobType: performance"
  interval: 24h
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  annotations:
    testgrid-dashboards: sig-scalability-network
    testgrid-tab-name: metric-measurement
  decorate: true
  decoration_config:
    timeout: 60m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --check-leaked-resources
      - --cluster=
      - --extract=ci/latest
      - --gcp-node-image=gci
      - --gcp-nodes=102
      - --provider=gce
      - --test=false
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=100
      - --test-cmd-args=--provider=gce
      - --test-cmd-args=--report-dir=/workspace/_artifacts
      - --test-cmd-args=--testsuite=testing/network/suite.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=40m
      - --use-logexporter
      resources:
        requests:
          cpu: 1
          memory: "2Gi"
        limits:
          cpu: 1
          memory: "2Gi"

- interval: 12h
  cluster: k8s-infra-prow-build
  name: ci-kubernetes-e2e-gci-gce-benchmark-requests-1
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 60m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-benchmarks
    testgrid-tab-name: gce-benchmark-requests-1
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --check-leaked-resources
      - --cluster=benchmark-small
      # Eliminate test flakiness
      - --env=ALLOWED_NOTREADY_NODES=1
      - --env=APISERVER_TEST_ARGS=--max-requests-inflight=1000 --max-mutating-requests-inflight=0 --profiling --contention-profiling
      - --env=CL2_BENCHMARK_INFLIGHT=1
      - --env=CL2_BENCHMARK_URI=/api/v1/namespaces/%namespace%/configmaps/benchmark-config-map-0?resourceVersion=0
      - --extract=ci/latest
      - --gcp-master-size=n2-standard-96
      - --gcp-node-image=gci
      - --gcp-node-size=e2-standard-8
      - --gcp-nodes=1
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-east1-b
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      - --test=false
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--experimental-gcp-snapshot-prometheus-disk=true
      - --test-cmd-args=--experimental-prometheus-disk-snapshot-name=$(JOB_NAME)-$(BUILD_ID)
      - --test-cmd-args=--experimental-prometheus-snapshot-to-report-dir=true
      - --test-cmd-args=--nodes=1
      - --test-cmd-args=--prometheus-scrape-kubelets=true
      - --test-cmd-args=--prometheus-scrape-node-exporter
      - --test-cmd-args=--provider=gce
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testconfig=testing/request-benchmark/config.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=45m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      resources:
        requests:
          cpu: 2
          memory: 6Gi
        limits:
          cpu: 2
          memory: 6Gi

- interval: 4h
  cluster: k8s-infra-prow-build
  name: ci-kubernetes-benchmark-list
  tags:
    - "perfDashPrefix: benchmark list"
    - "perfDashJobType: benchmarkList"
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 90m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-benchmarks
    testgrid-tab-name: gce-benchmark-list
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=benchmark-list
      - --extract=ci/latest
      - --gcp-master-size=n2-standard-32
      - --gcp-node-size=e2-standard-32
      - --gcp-node-image=gci
      - --gcp-nodes=1
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-east1-b
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      - --env=KUBE_FEATURE_GATES=DetectCacheInconsistency=false
      - --env=KUBE_GCE_PRIVATE_CLUSTER=false
      - --env=CL2_LIST_CONFIG_MAP_BYTES=100000
      - --env=CL2_LIST_CONFIG_MAP_NUMBER=10000
      - --env=CL2_LIST_BENCHMARK_PODS=10
      - --env=CL2_LIST_BENCHMARK_POD_CPU=2000
      - --env=CL2_LIST_BENCHMARK_POD_MEMORY=4096
      - --test=false
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=1
      - --test-cmd-args=--provider=gce
      - --test-cmd-args=--experimental-gcp-snapshot-prometheus-disk=true
      - --test-cmd-args=--experimental-prometheus-disk-snapshot-name=$(JOB_NAME)-$(BUILD_ID)
      - --test-cmd-args=--experimental-prometheus-snapshot-to-report-dir=true
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testconfig=testing/list/config.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=60m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      resources:
        requests:
          cpu: 3
          memory: "8Gi"
        limits:
          cpu: 3
          memory: "8Gi"

- interval: 4h
  cluster: k8s-infra-prow-build
  name: ci-kubernetes-benchmark-list-proto
  tags:
    - "perfDashPrefix: benchmark list proto"
    - "perfDashJobType: benchmarkList"
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 90m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-benchmarks
    testgrid-tab-name: gce-benchmark-list-proto
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=benchmark-list
      - --extract=ci/latest
      - --gcp-master-size=n2-standard-32
      - --gcp-node-size=e2-standard-32
      - --gcp-node-image=gci
      - --gcp-nodes=1
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-east1-b
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      - --env=KUBE_FEATURE_GATES=DetectCacheInconsistency=false
      - --env=KUBE_GCE_PRIVATE_CLUSTER=false
      - --env=CL2_LIST_CONFIG_MAP_BYTES=100000
      - --env=CL2_LIST_CONFIG_MAP_NUMBER=10000
      - --env=CL2_LIST_BENCHMARK_PODS=10
      - --env=CL2_LIST_BENCHMARK_POD_CPU=2000
      - --env=CL2_LIST_BENCHMARK_POD_MEMORY=4096
      - --env=CL2_LIST_BENCHMARK_CONTENT_TYPE=proto
      - --test=false
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--nodes=1
      - --test-cmd-args=--provider=gce
      - --test-cmd-args=--experimental-gcp-snapshot-prometheus-disk=true
      - --test-cmd-args=--experimental-prometheus-disk-snapshot-name=$(JOB_NAME)-$(BUILD_ID)
      - --test-cmd-args=--experimental-prometheus-snapshot-to-report-dir=true
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testconfig=testing/list/config.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=60m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      resources:
        requests:
          cpu: 3
          memory: "8Gi"
        limits:
          cpu: 3
          memory: "8Gi"

# Exploratory tests for resource size limit as proposed in https://github.com/kubernetes/kubernetes/issues/134375
- cron: '0 10 * * *' # Run on even days at 10:00 UTC
  name: ci-kubernetes-e2e-gce-scale-resource-size
  tags:
  - "perfDashPrefix: gce-5000Nodes-ResourceSize"
  - "perfDashBuildsCount: 270"
  - "perfDashJobType: performance"
  cluster: k8s-infra-prow-build
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  job_queue_name: "5k-gce-scale-test" # DON'T REMOVE THIS
  decorate: true
  decoration_config:
    timeout: 240m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-dashboards: sig-scalability-gce, google-gce
    testgrid-tab-name: gce-master-scale-resource-size
    description: "Exploratory tests for resource size limit as proposed in https://github.com/kubernetes/kubernetes/issues/134375"
  spec:
    volumes:
    - name: cache-secret
      secret:
        secretName: scale-pull-cache-token
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20251209-13d7d11b0f-master
      volumeMounts:
      - name: cache-secret
        readOnly: true
        mountPath: /etc/registry-auth
      env:
      - name: KUBERNETES_REGISTRY_PULL_THROUGH_HOST
        value: https://us-central1-docker.pkg.dev/v2/k8s-infra-e2e-scale-5k-project/k8s-5k-scale-cache/
      - name: KUBERNETES_REGISTRY_PULL_THROUGH_BASIC_AUTH_TOKEN_PATH
        value: /etc/registry-auth/token
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      # Override MASTER_SIZE to get additional memory to fit larger resource size.
      - --env=MASTER_SIZE=n2-standard-64 # 64 vCPUs, 256GB memory
      - --env=ETCD_QUOTA_BACKEND_BYTES=21474836480 # 20GB
      # Ensure exec-service is not scheduled on normal node of size e2-medium (2vCPUs, 4GB memory)
      - --env=CL2_EXECSERVICE_CPU_REQUESTS=2
      - --env=CL2_EXECSERVICE_MEMORY_REQUESTS=4Gi
      # Override for pod large resource size
      - --env=CL2_DAEMONSET_POD_PAYLOAD_SIZE=15360 # 15KB
      - --env=CL2_DEPLOYMENT_POD_PAYLOAD_SIZE=15360 # 15KB
      - --env=CL2_STATEFULSET_POD_PAYLOAD_SIZE=15360 # 15KB
      - --env=CL2_JOB_POD_PAYLOAD_SIZE=15360 # 15KB
      #  Remaining parameters should match ci-kubernetes-e2e-gce-scale-performance
      - --cluster=gce-scale-cluster
      - --env=HEAPSTER_MACHINE_TYPE=e2-standard-32
      # TODO(mborsz): Adjust or remove this change once we understand coredns
      # memory usage regression.
      - --env=KUBE_DNS_MEMORY_LIMIT=300Mi
      - --extract=ci/fast/latest-fast
      - --gcp-nodes=5000
      - --gcp-project-type=scalability-scale-project
      - --gcp-zone=us-east1-b
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      - --env=CL2_LOAD_TEST_THROUGHPUT=50
      - --env=CL2_DELETE_TEST_THROUGHPUT=50
      - --env=CL2_RATE_LIMIT_POD_CREATION=false
      - --env=KUBE_CONTROLLER_MANAGER_TEST_ARGS=--authorization-always-allow-paths=/healthz,/readyz,/livez,/metrics --endpointslice-updates-batch-period=500ms --endpoint-updates-batch-period=500ms
      # Overrides CONTROLLER_MANAGER_TEST_ARGS from preset-e2e-scalability-periodics.
      - --env=CONTROLLER_MANAGER_TEST_ARGS=--authorization-always-allow-paths=/healthz,/readyz,/livez,/metrics --profiling --contention-profiling --kube-api-qps=100 --kube-api-burst=100
      # Overrides SCHEDULER_TEST_ARGS from preset-e2e-scalability-periodics.
      # TODO(#1311): Clean this up after the experiment - it should allow
      #   to hugely decrease pod-startup-latency across the whole test.
      #   Given that individual controllers have separate QPS limits, we allow
      #   scheduler to keep up with the load from deployment, daemonset and job
      #   performing pod creations at once.
      - --env=SCHEDULER_TEST_ARGS=--authorization-always-allow-paths=/healthz,/readyz,/livez,/metrics --profiling --contention-profiling --kube-api-qps=500 --kube-api-burst=500
      # With APF only sum of --max-requests-inflight and --max-mutating-requests-inflight matters, so set --max-mutating-requests-inflight to 0.
      - --env=APISERVER_TEST_ARGS=--max-requests-inflight=640 --max-mutating-requests-inflight=0
      - --env=CL2_ENABLE_API_AVAILABILITY_MEASUREMENT=true
      - --env=CL2_API_AVAILABILITY_PERCENTAGE_THRESHOLD=99.5
      - --test=false
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--experimental-gcp-snapshot-prometheus-disk=true
      - --test-cmd-args=--experimental-prometheus-disk-snapshot-name=$(JOB_NAME)-$(BUILD_ID)
      - --test-cmd-args=--experimental-prometheus-snapshot-to-report-dir=true
      - --test-cmd-args=--nodes=5000
      - --test-cmd-args=--prometheus-scrape-node-exporter
      - --test-cmd-args=--provider=gce
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testconfig=testing/load/config.yaml
      - --test-cmd-args=--testconfig=testing/huge-service/config.yaml
      - --test-cmd-args=--testconfig=testing/access-tokens/config.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/enable_restart_count_check.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/ignore_known_gce_container_restarts.yaml
      - --test-cmd-args=--testoverrides=./testing/overrides/5000_nodes.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=420m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      resources:
        requests:
          cpu: 6
          memory: "32Gi"
        limits:
          cpu: 6
          memory: "32Gi"
