periodics:
# This is a sig-release-master-blocking job.
# The frequency was cut to reduce infrastructure costs.
- cron: '1 17 2-31/2 * *' # Run on even days at 9:01PST (17:01 UTC)
  name: ci-kubernetes-e2e-gce-scale-correctness
  cluster: k8s-infra-prow-build
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 270m
  annotations:
    testgrid-num-failures-to-alert: '2'
    testgrid-alert-email: kubernetes-sig-scale@googlegroups.com, kubernetes-scalability-tickets@google.com, release-team@kubernetes.io
    testgrid-dashboards: sig-release-master-informing, sig-scalability-gce, google-gce
    testgrid-tab-name: gce-master-scale-correctness
    # exclude-filter-by-regex=^(kubetest\.Test|ci-kubernetes-e2e-gce-scale-correctness\.Overall)$
    testgrid-base-options: 'exclude-filter-by-regex=%5E(kubetest%5C.Test%7Cci-kubernetes-e2e-gce-scale-correctness%5C.Overall)%24'
    description: "Uses kubetest to run correctness tests against a 5000-node cluster created with cluster/kube-up.sh"
  spec:
    volumes:
    - name: cache-secret
      secret:
        secretName: scale-pull-cache-token
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20241230-3006692a6f-master
      volumeMounts:
      - name: cache-secret
        readOnly: true
        mountPath: /etc/registry-auth
      env:
      - name: KUBERNETES_REGISTRY_PULL_THROUGH_HOST
        value: https://us-central1-docker.pkg.dev/v2/k8s-infra-e2e-scale-5k-project/k8s-5k-scale-cache/
      - name: KUBERNETES_REGISTRY_PULL_THROUGH_BASIC_AUTH_TOKEN_PATH
        value: /etc/registry-auth/token
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=gce-scale-cluster
      - --env=CONCURRENT_SERVICE_SYNCS=20 # support 20 LoadBalancer Services in parallel to deal with existing CI load #122286
      - --env=HEAPSTER_MACHINE_TYPE=e2-standard-32
      - --extract=ci/fast/latest-fast
      - --env=KUBE_CONTROLLER_MANAGER_TEST_ARGS=--endpointslice-updates-batch-period=500ms --endpoint-updates-batch-period=500ms
      # Overrides CONTROLLER_MANAGER_TEST_ARGS from preset-e2e-scalability-periodics.
      - --env=CONTROLLER_MANAGER_TEST_ARGS=--profiling --contention-profiling --kube-api-qps=100 --kube-api-burst=100
      - --gcp-master-image=gci
      - --gcp-node-image=gci
      - --gcp-node-size=e2-small
      - --gcp-nodes=5000
      - --gcp-project-type=scalability-scale-project
      - --gcp-ssh-proxy-instance-name=gce-scale-cluster-master
      - --gcp-zone=us-east1-b
      - --ginkgo-parallel=40
      - --provider=gce
      - --test_args=--ginkgo.skip=\[Driver:.gcepd\]|\[Serial\]|\[Disruptive\]|\[Flaky\]|\[Feature:([^L].*|L[^o].*|Lo[^a].*|Loa[^d].*)\] --minStartupPods=8 --node-schedulable-timeout=90m
      - --timeout=240m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      resources:
        requests:
          cpu: 6
          memory: "39Gi"
        limits:
          cpu: 6
          memory: "39Gi"

# This is a sig-release-master-blocking job.
# The frequency was cut to reduce infrastructure costs.
- cron: '1 17 1-31/2 * *' # Run on odd days at 9:01PST (17:01 UTC)
  name: ci-kubernetes-e2e-gce-scale-performance
  tags:
  - "perfDashPrefix: gce-5000Nodes"
  - "perfDashBuildsCount: 270"
  - "perfDashJobType: performance"
  cluster: k8s-infra-prow-build
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 450m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    testgrid-alert-email: kubernetes-sig-scale@googlegroups.com, kubernetes-scalability-tickets@google.com, release-team@kubernetes.io
    testgrid-dashboards: sig-release-master-informing, sig-scalability-gce, google-gce
    testgrid-tab-name: gce-master-scale-performance
    description: "Uses kubetest to run k8s.io/perf-tests/run-e2e.sh against a 5000-node cluster created with cluster/kube-up.sh"
  spec:
    volumes:
    - name: cache-secret
      secret:
        secretName: scale-pull-cache-token
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20241230-3006692a6f-master
      volumeMounts:
      - name: cache-secret
        readOnly: true
        mountPath: /etc/registry-auth
      env:
      - name: KUBERNETES_REGISTRY_PULL_THROUGH_HOST
        value: https://us-central1-docker.pkg.dev/v2/k8s-infra-e2e-scale-5k-project/k8s-5k-scale-cache/
      - name: KUBERNETES_REGISTRY_PULL_THROUGH_BASIC_AUTH_TOKEN_PATH
        value: /etc/registry-auth/token
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --cluster=gce-scale-cluster
      - --env=HEAPSTER_MACHINE_TYPE=e2-standard-32
      # TODO(mborsz): Adjust or remove this change once we understand coredns
      # memory usage regression.
      - --env=KUBE_DNS_MEMORY_LIMIT=300Mi
      - --extract=ci/fast/latest-fast
      - --gcp-nodes=5000
      - --gcp-project-type=scalability-scale-project
      - --gcp-zone=us-east1-b
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      - --env=CL2_LOAD_TEST_THROUGHPUT=50
      - --env=CL2_DELETE_TEST_THROUGHPUT=50
      - --env=CL2_RATE_LIMIT_POD_CREATION=false
      - --env=KUBE_CONTROLLER_MANAGER_TEST_ARGS=--endpointslice-updates-batch-period=500ms --endpoint-updates-batch-period=500ms
      # Overrides CONTROLLER_MANAGER_TEST_ARGS from preset-e2e-scalability-periodics.
      - --env=CONTROLLER_MANAGER_TEST_ARGS=--profiling --contention-profiling --kube-api-qps=100 --kube-api-burst=100
      # Overrides SCHEDULER_TEST_ARGS from preset-e2e-scalability-periodics.
      # TODO(#1311): Clean this up after the experiment - it should allow
      #   to hugely decrease pod-startup-latency across the whole test.
      #   Given that individual controllers have separate QPS limits, we allow
      #   scheduler to keep up with the load from deployment, daemonset and job
      #   performing pod creations at once.
      - --env=SCHEDULER_TEST_ARGS=--profiling --contention-profiling --kube-api-qps=500 --kube-api-burst=500
      # With APF only sum of --max-requests-inflight and --max-mutating-requests-inflight matters, so set --max-mutating-requests-inflight to 0.
      - --env=APISERVER_TEST_ARGS=--max-requests-inflight=640 --max-mutating-requests-inflight=0
      - --env=CL2_ENABLE_API_AVAILABILITY_MEASUREMENT=true
      - --env=CL2_API_AVAILABILITY_PERCENTAGE_THRESHOLD=99.5
      - --test=false
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--experimental-gcp-snapshot-prometheus-disk=true
      - --test-cmd-args=--experimental-prometheus-disk-snapshot-name=$(JOB_NAME)-$(BUILD_ID)
      - --test-cmd-args=--experimental-prometheus-snapshot-to-report-dir=true
      - --test-cmd-args=--nodes=5000
      - --test-cmd-args=--prometheus-scrape-node-exporter
      - --test-cmd-args=--provider=gce
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testconfig=testing/load/config.yaml
      - --test-cmd-args=--testconfig=testing/huge-service/config.yaml
      - --test-cmd-args=--testconfig=testing/access-tokens/config.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/enable_restart_count_check.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/ignore_known_gce_container_restarts.yaml
      - --test-cmd-args=--testoverrides=./testing/overrides/5000_nodes.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=420m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      resources:
        requests:
          cpu: 6
          memory: "16Gi"
        limits:
          cpu: 6
          memory: "16Gi"

- interval: 30m
  cluster: k8s-infra-prow-build
  name: ci-kubernetes-e2e-gci-gce-scalability
  tags:
  - "perfDashPrefix: gce-100Nodes-master"
  - "perfDashJobType: performance"
  - "perfDashBuildsCount: 500"
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-e2e-scalability-common: "true"
    preset-e2e-scalability-periodics: "true"
    preset-e2e-scalability-periodics-master: "true"
  decorate: true
  decoration_config:
    timeout: 140m
  extra_refs:
  - org: kubernetes
    repo: kubernetes
    base_ref: master
    path_alias: k8s.io/kubernetes
  - org: kubernetes
    repo: perf-tests
    base_ref: master
    path_alias: k8s.io/perf-tests
  annotations:
    fork-per-release: "true"
    fork-per-release-cron: 0 */6 * * *, 0 0/12 * * *, 0 4-16/12 * * *, 0 8-20/12 * * *, 0 8-20/24 * * *
    fork-per-release-deletions: "preset-e2e-scalability-periodics-master"
    fork-per-release-replacements: "--extract=ci/fast/latest-fast -> --extract=ci/latest-{{.Version}}, gce-100Nodes-master -> gce-100Nodes-{{.Version}}"
    testgrid-dashboards: sig-release-master-blocking, sig-scalability-gce
    testgrid-tab-name: gce-cos-master-scalability-100
    testgrid-alert-email: kubernetes-sig-scale@googlegroups.com, kubernetes-scalability-tickets@google.com
    description: "Uses kubetest to run k8s.io/perf-tests/run-e2e.sh against a 100-node cluster created with cluster/kube-up.sh"
    testgrid-num-failures-to-alert: '2'
  spec:
    containers:
    - image: gcr.io/k8s-staging-test-infra/kubekins-e2e:v20241230-3006692a6f-master
      command:
      - runner.sh
      - /workspace/scenarios/kubernetes_e2e.py
      args:
      - --check-leaked-resources
      - --cluster=e2e-big
      - --env=APISERVER_TEST_ARGS=--max-requests-inflight=80 --max-mutating-requests-inflight=0 --profiling --contention-profiling
      - --env=HEAPSTER_MACHINE_TYPE=e2-standard-8
      - --extract=ci/fast/latest-fast
      - --gcp-node-image=gci
      - --gcp-nodes=100
      - --gcp-project-type=scalability-project
      - --gcp-zone=us-east1-b
      - --provider=gce
      - --metadata-sources=cl2-metadata.json
      - --env=CL2_ENABLE_DNS_PROGRAMMING=true
      - --env=CL2_SCHEDULER_THROUGHPUT_THRESHOLD=0
      - --env=CL2_ENABLE_API_AVAILABILITY_MEASUREMENT=true
      - --env=CL2_API_AVAILABILITY_PERCENTAGE_THRESHOLD=99.5
      - --test=false
      - --test-cmd=$GOPATH/src/k8s.io/perf-tests/run-e2e.sh
      - --test-cmd-args=cluster-loader2
      - --test-cmd-args=--experimental-gcp-snapshot-prometheus-disk=true
      - --test-cmd-args=--experimental-prometheus-disk-snapshot-name=$(JOB_NAME)-$(BUILD_ID)
      - --test-cmd-args=--experimental-prometheus-snapshot-to-report-dir=true
      - --test-cmd-args=--nodes=100
      - --test-cmd-args=--prometheus-scrape-kubelets=true
      - --test-cmd-args=--prometheus-scrape-node-exporter
      - --test-cmd-args=--provider=gce
      - --test-cmd-args=--report-dir=$(ARTIFACTS)
      - --test-cmd-args=--testconfig=testing/load/config.yaml
      - --test-cmd-args=--testconfig=testing/huge-service/config.yaml
      - --test-cmd-args=--testconfig=testing/access-tokens/config.yaml
      # TODO(oxddr): re-enable this once we understand its impact on tests, https://github.com/kubernetes/kubernetes/issues/89051
      # - --test-cmd-args=--testoverrides=./testing/chaosmonkey/override.yaml
      # - --test-cmd-args=--testoverrides=./testing/chaosmonkey/ignore_node_killer_container_restarts_100.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/enable_restart_count_check.yaml
      - --test-cmd-args=--testoverrides=./testing/experiments/use_simple_latency_query.yaml
      - --test-cmd-args=--testoverrides=./testing/overrides/load_throughput.yaml
      - --test-cmd-name=ClusterLoaderV2
      - --timeout=120m
      - --use-logexporter
      - --logexporter-gcs-path=gs://k8s-infra-scalability-tests-logs/$(JOB_NAME)/$(BUILD_ID)
      resources:
        requests:
          cpu: 2
          memory: 6Gi
        limits:
          cpu: 2
          memory: 6Gi
